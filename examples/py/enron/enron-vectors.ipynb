{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6785c319",
   "metadata": {},
   "source": [
    "# Using Raphtory similarity search to uncover Enron criminal network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd195489",
   "metadata": {},
   "source": [
    "The Enron scandal was one of the largest corporate fraud cases in history, leading to the downfall of the company and the conviction of several executives. The graph below illustrates the significant decline in Enron's stock price between August 2000 and December 2001, providing valuable insights into the company's downfall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ce5767",
   "metadata": {},
   "source": [
    "![enron stock price](https://upload.wikimedia.org/wikipedia/commons/thumb/d/d0/EnronStockPriceAugust2000toJanuary2001.svg/567px-EnronStockPriceAugust2000toJanuary2001.svg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd830e1",
   "metadata": {},
   "source": [
    "Some important nodes in Enron networks, implicated or not in the case, are the following:\n",
    "- kenneth.lay: Kenneth Lay (CEO)\n",
    "- andrew.fastow: Andrew Fastow (CFO)\n",
    "- louise.kitchen: Louise Kitchen (Managing Director)\n",
    "- j.kaminski: Vincent Kaminski (Managing Director for Research, raised strong objections to the financial practices of Andrew Fastow)\n",
    "- a..shankman: Jeffrey Adam Shankman (Head of the global markets division, charged with White Collard Crime)\n",
    "- michelle.cash: Michelle Cash (Assistant General Counsel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e773f6e",
   "metadata": {},
   "source": [
    "Now, imagine being the judge in this case, facing a dataset with hundreds of thousands of emails and having the responsability of finding all the criminals and stuff involved. How much time would you need to find all of them and their relationships.\n",
    "\n",
    "Well, hold tight because Raphtory supports now similarity search out of the box. This means we can quickly seearch over the whole network of emails messages to spot various types of crime just by submitting some semantic query regarding the crimes we are interested in disclosure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e9e834",
   "metadata": {},
   "source": [
    "## Wait how does this work? And what is similarity search in the first place?\n",
    "\n",
    "Similarity search is nothing new. It's a technique that allows you to search among a set of documents those that are more similar from a semantic perspective so some given query.\n",
    "\n",
    "For instance, the query might be `hiding information`. If we submit that query over a set of documents containing email messages, we are likely going to have returned those documents which in some way talk about hiding information.\n",
    "\n",
    "And which role does that play in Raphtory land? In order to cross the bridge, we need to somehow be able to represent the entities in some graphs or some parts of them as documents. Then, this documents can be translated into embeddings or vectors using some embedding function so we can search over them. We call this in Raphtory vectorising a graph, and it is as easy as:\n",
    "\n",
    "```\n",
    "vg = g.vectorise(embeddding_function)\n",
    "```\n",
    "\n",
    "Raphtory has a default way to translate graph entities into documents. However, if we have a deep understanding of the semantics living in our graph, we can always create those documents ourselves, insert them as properties, and let Raphtory know which property use to pick them up:\n",
    "\n",
    "```\n",
    "vg = g.vectorise(embeddding_function, nodes=\"document\", edges=\"document\")\n",
    "```\n",
    "\n",
    "And that is it. Now running a similarity search query against the graph becomes trivial. We just need to use some of the methods available in the VectorisedGraph to select some documents using a query and then get the documents.\n",
    "\n",
    "```\n",
    "vg.append_by_similarity('hiding information', limit=10).get_documents()\n",
    "```\n",
    "\n",
    "This was a basic query, but you have many more methods available that allow you to implement complex similarity search algorithms leveraging the graph space between documents. \n",
    "\n",
    "Now that we have all the basics, let's get started trying to find some criminals!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b353c608",
   "metadata": {},
   "source": [
    "### Imports and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1ceb7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "from raphtory import *\n",
    "from raphtory import algorithms\n",
    "from raphtory.vectors import *\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from email.utils import parsedate_to_datetime, parsedate\n",
    "from datetime import timezone, datetime\n",
    "from time import mktime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "284613f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4d17fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe915bfa",
   "metadata": {},
   "source": [
    "### Ingesting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44921a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions for the parsing of the enron dataset\n",
    "\n",
    "def extract_sender(text):\n",
    "    sender_cut = text.split(\"\\nFrom: \")\n",
    "    if len(sender_cut) > 1:\n",
    "        email_cut =  sender_cut[1].split(\"\\n\")[0].split(\"@\")\n",
    "        if len(email_cut) > 1:\n",
    "            return email_cut[0]\n",
    "        else: \n",
    "            return\n",
    "    else:\n",
    "        return\n",
    "    \n",
    "def extract_sender_domain(text):\n",
    "    sender_cut = text.split(\"\\nFrom: \")\n",
    "    if len(sender_cut) > 1:\n",
    "        email_cut =  sender_cut[1].split(\"\\n\")[0].split(\"@\")\n",
    "        if len(email_cut) > 1:\n",
    "            return email_cut[1]\n",
    "        else: \n",
    "            return\n",
    "    else:\n",
    "        return\n",
    "    \n",
    "def extract_recipient(text):\n",
    "    recipient_cut = text.split(\"\\nTo: \")\n",
    "    if len(recipient_cut) > 1:\n",
    "        email_cut = recipient_cut[1].split(\"\\n\")[0].split(\"@\")\n",
    "        if len(email_cut) > 1:\n",
    "            return email_cut[0]\n",
    "        else:\n",
    "            return\n",
    "    else:\n",
    "        return\n",
    "    \n",
    "def extract_actual_message(text):\n",
    "    try:\n",
    "        body = re.split(\"X-FileName: .*\\n\\n\", text)[1]\n",
    "        return re.split('-{3,}\\s*Original Message\\s*-{3,}', body)[0][:1000]\n",
    "    except:\n",
    "        return\n",
    "\n",
    "extract_date = lambda text: text.split(\"Date: \")[1].split(\"\\n\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b802e82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We ingest the email dataset and carry out some cleaning using pandas\n",
    "enron = pd.DataFrame()\n",
    "enron['email'] = pd.read_csv('emails.csv', usecols=['message'])['message']\n",
    "enron['src'] = enron['email'].apply(extract_sender)\n",
    "enron['dst'] = enron['email'].apply(extract_recipient)\n",
    "enron['time'] = enron['email'].apply(extract_date)\n",
    "enron['message'] = enron['email'].apply(extract_actual_message)\n",
    "enron['message'] = enron['message'].str.strip()\n",
    "\n",
    "enron = enron.dropna(subset=[\"src\", \"dst\", \"time\", \"message\"])\n",
    "enron = enron.drop_duplicates(['src', 'dst', 'time', 'message'])\n",
    "enron = enron[enron['message'].str.len() > 5]\n",
    "enron = enron[enron['dst'] != 'undisclosed.recipients']\n",
    "enron = enron[enron['email'].apply(extract_sender_domain) == 'enron.com']\n",
    "\n",
    "enron['document'] = enron['src'] + \" sent a message to \" + enron['dst'] + \" at \" + enron['time'] + \" with the following content:\\n\" + enron['message']\n",
    "\n",
    "# And then we ingest those emails into a Raphtory graph, where the nodes are people,\n",
    "# most of them belonging to Enron, and the edges are emails sent between them\n",
    "raw_graph = Graph()\n",
    "def ingest_edge(record):\n",
    "    e = raw_graph.add_edge(record['time'], record['src'], record['dst'], {'document': record['document']})\n",
    "    raw_graph.add_vertex(record['time'], record['src']).add_constant_properties({'document': ''})\n",
    "    raw_graph.add_vertex(record['time'], record['dst']).add_constant_properties({'document': ''})\n",
    "enron.apply(ingest_edge, axis=1)\n",
    "\n",
    "# Finally we apply a window around the most interesting time period of the Enron bankrupty,\n",
    "# the last 4 months of 2001\n",
    "g = raw_graph.window('2001-09-01 00:00:00', '2002-01-01 00:00:00') # 4 months\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7178050",
   "metadata": {},
   "source": [
    "And here our vectors module starts playing its role. We first vectorise the graph we just built. For that, as we explained before, we need to use an embedding function that translates documents into vectors. For this task we are going to pick up one model from langchain that can run locally, `gte-small`. Bear in mind that this is computationally very expensive. If we run this from a fresh start, that task will take hours to complete. But don't worry, to ease this, the vectorising process allows you to set up a cache file, so that if we find the embeddings for a document in it, we just grab it and avoid calling the expensive model. We already did this for you and so, there is already a file `embedding-cache` in the current directory that will successfully contain all the embeddings we need today."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79cd8203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing embeddings for nodes\n",
      "computing embeddings for edges\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"thenlper/gte-small\")\n",
    "embedding_function = lambda texts: embeddings.embed_documents(texts)\n",
    "\n",
    "v = g.vectorise(\n",
    "    embedding_function,\n",
    "    \"./embedding-cache\",\n",
    "    node_document=\"document\",\n",
    "    edge_document=\"document\",\n",
    "    verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f901b3",
   "metadata": {},
   "source": [
    "### Running queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3d7c09",
   "metadata": {},
   "source": [
    "Congratulations! you successfully loaded a vectorised graph containing four months of the Enron email dataset. Now you can submit any queries you want to try and find the criminal network hide behind this complex spider web. For instance, one of the presunt crimes that were commited was hiding information that later on lead to the bankruty. Let's try to find those interactions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8399569f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eric.thode sent a message to louise.kitchen at Tue, 2 Oct 2001 06:22:21 -0700 (PDT) with the following content:\n",
      "I guess this means everyone knows!  You just can't hide.\n",
      "===========================================================================================\n",
      "david.port sent a message to john.lavorato at Mon, 19 Nov 2001 07:51:54 -0800 (PST) with the following content:\n",
      "i knew you would be hiding somewhere\n",
      "i am afraid i'm going to have to tell on you\n",
      "===========================================================================================\n",
      "andy.rodriquez sent a message to charles.yeung at Tue, 23 Oct 2001 10:29:29 -0700 (PDT) with the following content:\n",
      "NERC is apparently moving forward aggressively on their initiative to restrict access to market information.  Doug Sewell, who participates on the MAIN Planning Committee, was on a call this morning in which members of MAIN and NERC's Virginia Sulzberger discussed ways to limit access to information.  A new disturbing angle was that apparently, some members indirectly alleged that marketers have \"higher turnover\" and \"loose lips,\" and were using this as a scare tactic to indicate why the information should be restricted (potentially even from legitimate consumers like us).\n",
      "\n",
      "If I remember correctly, we were going to contact NERC to let them know our opinions on this issue.  It sounds like perhaps they are not being addressed sufficiently.  Doug has suggested we should being it up at the MAIN MIC meeting; do we want to begin a campaign to protect our access to this data?  I think that without getting more involved, this will be yet another industry \"de facto\" standard that is created und\n",
      "===========================================================================================\n",
      "m..presto sent a message to rogers.herndon at Wed, 26 Sep 2001 09:19:37 -0700 (PDT) with the following content:\n",
      "How exactly are we exposed?\n",
      "===========================================================================================\n",
      "d..steffes sent a message to susan.scott at Thu, 6 Sep 2001 10:30:08 -0700 (PDT) with the following content:\n",
      "I wanted to re-confirm that you are covering?\n",
      "\n",
      "Thanks,\n",
      "\n",
      "Jim\n",
      "===========================================================================================\n",
      "michelle.cash sent a message to tana.cashion at Tue, 27 Nov 2001 14:36:43 -0800 (PST) with the following content:\n",
      "I'd like a copy of that, if possible.\n",
      "\n",
      "I think it should state:  Confidential and Proprietary -- Not to be Disclosed to Persons Other Than Human Resources and Legal Department.  If possible, put it on all documents, as well as the cover of the notebook.  \n",
      "\n",
      "Michelle\n",
      "===========================================================================================\n",
      "travis.mccullough sent a message to mitch.taylor at Thu, 25 Oct 2001 20:48:33 -0700 (PDT) with the following content:\n",
      "Attached is a revised version of the CA with Goldman.  The remaining issue is in Section 1 regarding restrictions on Goldman's \"use\" of the Confidential Information.  Goldman believes that they will have to bring a lot of their personnel, including traders, \"over the wall\" in order to perform this engagement, and that such personnel will by necessity see some of our Confidential Information.  While they agree that their personnel shouldn't be able to use our specific information against us in future transactions, they are worried that the restriction on their use of our info that is set out in Section 1 could limit the future activities of those folks simply because they \"saw\" some of our Confidential Information and are carrying it around in their heads, and at any time could be accused of \"using\" our info.\n",
      " \n",
      "Initially, Goldman insisted on removing the restriction on use. We have suggested the language at the end of Section , which would generally restrict use of the information to th\n",
      "===========================================================================================\n",
      "frazier.king sent a message to rod.hayslett at Tue, 13 Nov 2001 09:25:10 -0800 (PST) with the following content:\n",
      "Rod and Joe,\n",
      "\n",
      "Here is a proposed write up of the procedures we use to protect the data that we send to RAC.\n",
      "Please take a look and give me your comments.\n",
      "Thanks!\n",
      "\n",
      "Frazier\n",
      "===========================================================================================\n",
      "rahil.jafry sent a message to kay.mann at Mon, 22 Oct 2001 15:18:54 -0700 (PDT) with the following content:\n",
      "Kay,\n",
      "\n",
      "I just checked our first presentation to them, and it didn't have the \"confidential stamp on them.  Ideally, we'd like to have that covered, but don't think it is critical if the information there is not.\n",
      "\n",
      "Going forward, I believe our revised proposal already has the stamp on every page.  If not, we will ensure that it is marked.\n",
      "\n",
      "Are you guys okay with everything else?\n",
      "\n",
      "- R\n",
      "===========================================================================================\n",
      "heather.dunton sent a message to mike.swerzbin at Tue, 6 Nov 2001 16:13:11 -0800 (PST) with the following content:\n",
      "The next phase of Curve Manager enables security on who marks your curves.\n",
      "Please reply back w/ who you want access to modifying your curves.\n",
      "\n",
      "Thanks,\n",
      "Heather\n",
      "===========================================================================================\n"
     ]
    }
   ],
   "source": [
    "documents = v.append_edges_by_similarity(\"hiding information\", 10).get_documents()\n",
    "for doc in documents:\n",
    "    print(doc.content)\n",
    "    print('===========================================================================================')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d12956",
   "metadata": {},
   "outputs": [],
   "source": [
    "And here it is, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af7ae2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement an example of Langchain retriever using raphtory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "raphtory",
   "language": "python",
   "name": "raphtory"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
