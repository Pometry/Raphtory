#https://doc.akka.io/docs/akka/current/general/configuration-reference.html

Raphtory {
    builderServers        = 1
    partitionServers      = 1
    buildersPerServer     = 5
    partitionsPerServer   = 5
}

settings {

//  hostname = ${?HOSTNAME}
//	ip		   = ${?HOST_IP} // original was localhost/
//	externalip = ${SEEDNODE_SERVICE_HOST}
//=======
	hostname = ${?HOSTNAME}
	kubeip	 = ${?SEEDNODE_SERVICE_HOST} // original was localhost/
	ip       = ${?HOST_IP}
//>>>>>>> e543c2050359453e428f41c0cfe96cc60aa37521
	//hostName = "localhost"
	//ip = 0.0.0.0
	http 		 = 8080
	#port 		 = 1400
	#port     = ${?HOST_PORT}
	#bport		 = 1400
    #bport    = ${?HOST_PORT}
}
akka.cluster.jmx.multi-mbeans-in-same-jvm = on
akka.management.cluster.bootstrap.contact-point-discovery {
	discovery-method = kubernetes-api
}



akka.logger-startup-timeout = 30s
akka.actor.warn-about-java-serializer-usage=false
akka {
	log-dead-letters = 10
	log-dead-letters-during-shutdown = on
	extensions = ["akka.cluster.pubsub.DistributedPubSub"]
	loglevel = "INFO"
	loggers = ["akka.event.slf4j.Slf4jLogger"]
	stdout-loglevel = "INFO"
	#log-config-on-start = on


	discovery {
		method = kubernetes-api
		method = ${?AKKA_DISCOVERY_METHOD}
		kubernetes-api {
			pod-namespace = "default" // in which namespace cluster is running
			pod-namespace = ${?AKKA_NAMESPACE}
			pod-label-selector = "app=akka-simple-cluster" // selector - hot to find other cluster nodes
			pod-label-selector = ${?AKKA_POD_LABEL_SELECTOR}
			pod-port-name = "management" // name of cluster management port
			pod-port-name = ${?AKKA_MANAGEMENT_PORT_NAME}
		}
	}

	actor.allow-java-serialization = on
	actor.warn-about-java-serializer-usage = on

	actor {
		#provider = cluster
		provider = akka.cluster.ClusterActorRefProvider
		#serialize-messages = on
		serializers {
			proto = "akka.remote.serialization.ProtobufSerializer"
			kryo = "io.altoo.akka.serialization.kryo.KryoSerializer"
		}
		debug {
			# enable function of LoggingReceive, which is to log any received message at
			# DEBUG level
			receive = off
		}
		serialization-bindings {
			"com.raphtory.core.components.leader.WatchDog$Message$RequestBuilderId$" = kryo
			"com.raphtory.core.components.leader.WatchDog$Message$ClusterStatusRequest$" = kryo
			"com.raphtory.core.components.leader.WatchDog$Message$RequestPartitionId$" = kryo
			"com.raphtory.core.components.leader.WatchDog$Message$RequestSpoutId$" = kryo
			"com.raphtory.core.components.leader.WatchDog$Message$RequestQueryId$" = kryo
			"com.raphtory.core.components.leader.WatchDog$Message$PartitionsCount" = kryo
			"com.raphtory.core.components.leader.WatchDog$Message$ClusterStatusResponse" = kryo
			"com.raphtory.core.components.leader.WatchDog$Message$AssignedId" = kryo
			"com.raphtory.core.components.leader.WatchDog$Message$BuilderUp" = kryo
			"com.raphtory.core.components.leader.WatchDog$Message$SpoutUp" = kryo
			"com.raphtory.core.components.leader.WatchDog$Message$QueryManagerUp" = kryo
			"com.raphtory.core.components.leader.WatchDog$Message$PartitionUp" = kryo
			"com.raphtory.core.components.leader.WatchDog$Message$RequestPartitionCount$" = kryo

			"com.raphtory.core.components.leader.WatermarkManager$Message$ProbeWatermark$" = kryo
			"com.raphtory.core.components.leader.WatermarkManager$Message$WatermarkTime$" = kryo
			"com.raphtory.core.components.leader.WatermarkManager$Message$SaveState$" = kryo
			"com.raphtory.core.components.leader.WatermarkManager$Message$WatermarkTime" = kryo

			"com.raphtory.core.components.spout.SpoutAgent$CommonMessage$SpoutOnline$" = kryo
			"com.raphtory.core.components.spout.SpoutAgent$CommonMessage$WorkPlease$" = kryo
			"com.raphtory.core.components.spout.SpoutAgent$CommonMessage$AllocateTuple" = kryo
			"com.raphtory.core.components.spout.SpoutAgent$CommonMessage$DataFinished$" = kryo
			"com.raphtory.core.components.spout.SpoutAgent$CommonMessage$NoWork$" = kryo

			"com.raphtory.core.components.graphbuilder.BuilderExecutor$CommonMessage$BuilderTimeSync" = kryo
			"com.raphtory.core.components.graphbuilder.BuilderExecutor$CommonMessage$DataFinishedSync" = kryo
			"com.raphtory.core.components.graphbuilder.BuilderExecutor$CommonMessage$KeepAlive$" = kryo

			"com.raphtory.core.model.graph.TrackedGraphUpdate" = kryo
			"com.raphtory.core.model.graph.VertexAdd" = kryo
			"com.raphtory.core.model.graph.EdgeAdd" = kryo
			"com.raphtory.core.model.graph.VertexDelete" = kryo
			"com.raphtory.core.model.graph.EdgeDelete" = kryo
			"com.raphtory.core.model.graph.Properties" = kryo
			"com.raphtory.core.model.graph.DoubleProperty" = kryo
			"com.raphtory.core.model.graph.ImmutableProperty" = kryo
			"com.raphtory.core.model.graph.StringProperty" = kryo
			"com.raphtory.core.model.graph.LongProperty" = kryo
			"com.raphtory.core.model.graph.DoubleProperty" = kryo
			"com.raphtory.core.model.graph.Type" = kryo

			"com.raphtory.core.model.graph.TrackedGraphEffect" = kryo
			"com.raphtory.core.model.graph.SyncNewEdgeAdd" = kryo
            "com.raphtory.core.model.graph.SyncExistingEdgeAdd" = kryo
            "com.raphtory.core.model.graph.SyncExistingEdgeRemoval" = kryo
            "com.raphtory.core.model.graph.SyncNewEdgeRemoval" = kryo
            "com.raphtory.core.model.graph.OutboundEdgeRemovalViaVertex" = kryo
            "com.raphtory.core.model.graph.InboundEdgeRemovalViaVertex" = kryo
            "com.raphtory.core.model.graph.SyncExistingRemovals" = kryo

			"com.raphtory.core.model.graph.EdgeSyncAck" = kryo
			"com.raphtory.core.model.graph.VertexRemoveSyncAck" = kryo

			"com.raphtory.core.model.graph.VertexMessage" = kryo
			"com.raphtory.core.components.querymanager.QueryHandler$Message$StartAnalysis$" = kryo
			"com.raphtory.core.components.querymanager.QueryHandler$Message$ReaderWorkersOnline$" = kryo
			"com.raphtory.core.components.querymanager.QueryHandler$Message$ReaderWorkersAck$" = kryo
			"com.raphtory.core.components.querymanager.QueryHandler$Message$LoadAnalyser" = kryo
			"com.raphtory.core.components.querymanager.QueryHandler$Message$ExecutorEstablished" = kryo
			"com.raphtory.core.components.querymanager.QueryHandler$Message$TimeCheck$" = kryo
			"com.raphtory.core.components.querymanager.QueryHandler$Message$TimeResponse" = kryo
			"com.raphtory.core.components.querymanager.QueryHandler$Message$RecheckTime$" = kryo
			"com.raphtory.core.components.querymanager.QueryHandler$Message$CreatePerspective" = kryo
			"com.raphtory.core.components.querymanager.QueryHandler$Message$PerspectiveEstablished$" = kryo
			"com.raphtory.core.components.querymanager.QueryHandler$Message$StartSubtask" = kryo
			"com.raphtory.core.components.querymanager.QueryHandler$Message$Ready" = kryo
			"com.raphtory.core.components.querymanager.QueryHandler$Message$SetupNextStep" = kryo
			"com.raphtory.core.components.querymanager.QueryHandler$Message$SetupNextStepDone$" = kryo
			"com.raphtory.core.components.querymanager.QueryHandler$Message$StartNextStep" = kryo
			"com.raphtory.core.components.querymanager.QueryHandler$Message$CheckMessages" = kryo
			"com.raphtory.core.components.querymanager.QueryHandler$Message$GraphFunctionComplete" = kryo
			"com.raphtory.core.components.querymanager.QueryHandler$Message$EndStep" = kryo
			"com.raphtory.core.components.querymanager.QueryHandler$Message$Finish" = kryo
			"com.raphtory.core.components.querymanager.QueryHandler$Message$ReturnResults" = kryo
			"com.raphtory.core.components.querymanager.QueryHandler$Message$StartNextSubtask$" = kryo
			"com.raphtory.core.components.querymanager.QueryManager$Message$KillTask" = kryo
            "com.raphtory.core.components.querymanager.QueryManager$Message$JobKilled$" = kryo
            "com.raphtory.core.components.querymanager.QueryManager$Message$ResultsForApiPI" = kryo
            "com.raphtory.core.components.querymanager.QueryManager$Message$JobDoesntExist$" = kryo
            "com.raphtory.core.components.querymanager.QueryManager$Message$ManagingTask" = kryo
            "com.raphtory.core.components.querymanager.QueryManager$Message$AreYouFinished$" = kryo
            "com.raphtory.core.components.querymanager.QueryManager$Message$TaskFinished" = kryo
            "com.raphtory.core.components.querymanager.QueryManager$Message$JobFailed$" = kryo

            "com.raphtory.core.components.querymanager.QueryHandler$Message$EstablishExecutor"= kryo
            "com.raphtory.core.components.querymanager.QueryHandler$Message$ExecutorEstablished"= kryo
            "com.raphtory.core.components.querymanager.QueryHandler$Message$StartGraph$"= kryo
            "com.raphtory.core.components.querymanager.QueryHandler$Message$TableBuilt$"= kryo
            "com.raphtory.core.components.querymanager.QueryHandler$Message$TableFunctionComplete$"= kryo
            "com.raphtory.core.components.querymanager.QueryHandler$Message$CreatePerspective"= kryo
            "com.raphtory.core.components.querymanager.QueryHandler$Message$PerspectiveEstablished$"= kryo

            "com.raphtory.core.components.querymanager.QueryManager$Message$PointQuery"= kryo
            "com.raphtory.core.components.querymanager.QueryManager$Message$RangeQuery"= kryo
            "com.raphtory.core.components.querymanager.QueryManager$Message$LiveQuery"= kryo
            "com.raphtory.core.components.querymanager.QueryManager$Message$EndQuery"= kryo
            "com.raphtory.core.components.querymanager.QueryManager$Message$QueryNotPresent"= kryo

            "com.raphtory.core.model.algorithm.Step"= kryo
            "com.raphtory.core.model.algorithm.Iterate"= kryo
            "com.raphtory.core.model.algorithm.VertexFilter"= kryo
            "com.raphtory.core.model.algorithm.Select"= kryo
            "com.raphtory.core.model.algorithm.TableFilter"= kryo
            "com.raphtory.core.model.algorithm.WriteTo"= kryo

            "com.raphtory.core.components.leader.WatermarkManager$Message$WhatsTheTime$" = kryo

			"com.raphtory.dev.wordSemantic.spouts.Update" = kryo



			#"scala.collection.mutable.TreeMap" = kryo
			#"scala.None$" = kryo
			#"scala.collection.immutable.$colon$colon" = kryo

            "com.raphtory.algorithms.PartitionState"=kryo
		}

	}
	bounded-mailbox {
		mailbox-type = "akka.dispatch.NonBlockingBoundedMailbox"
		mailbox-capacity = 200000000
	}

	actor.mailbox.requirements {
		"akka.dispatch.BoundedMessageQueueSemantics" = bounded-mailbox
	}
	remote {
		artery {
			transport = tcp
			//log-sent-messages = on#
			//log-received-messages = on
			//log-frame-size-exceeding = 1200000b
 			advanced {
				outbound-message-queue-size = 1000000
				maximum-frame-size = 2MB
				outbound-control-queue-size = 1000000
			}

		}
		artery.canonical {

			#bind-hostname = 0.0.0.0
			#bind-hostname = ${?HOST_IP}
			#bind-port     = ${settings.bport}

			hostname = ${?HOST_IP}
			hostname = ${?SEEDNODE_SERVICE_HOST}

			#port     = ${settings.port}
		}
	}

	failure-detector {

		# FQCN of the failure detector implementation.
		# It must implement akka.remote.FailureDetector and have
		# a public constructor with a com.typesafe.config.Config and
		# akka.actor.EventStream parameter.
		implementation-class = "akka.remote.PhiAccrualFailureDetector"

		# How often keep-alive heartbeat messages should be sent to each connection.
		heartbeat-interval = 10 s

		# Defines the failure detector threshold.
		# A low threshold is prone to generate many wrong suspicions but ensures
		# a quick detection in the event of a real crash. Conversely, a high
		# threshold generates fewer mistakes but needs more time to detect
		# actual crashes.
		threshold = 30

		# Number of the samples of inter-heartbeat arrival times to adaptively
		# calculate the failure timeout for connections.
		max-sample-size = 1000

		# Minimum standard deviation to use for the normal distribution in
		# AccrualFailureDetector. Too low standard deviation might result in
		# too much sensitivity for sudden, but normal, deviations in heartbeat
		# inter arrival times.
		min-std-deviation = 100 ms

		# Number of potentially lost/delayed heartbeats that will be
		# accepted before considering it to be an anomaly.
		# This margin is important to be able to survive sudden, occasional,
		# pauses in heartbeat arrivals, due to for example garbage collect or
		# network drop.
		acceptable-heartbeat-pause = 10 s

		# Number of member nodes that each member will send heartbeat messages to,
		# i.e. each node will be monitored by this number of other nodes.
		monitored-by-nr-of-members = 5

		# After the heartbeat request has been sent the first failure detection
		# will start after this period, even though no heartbeat message has
		# been received.
		expected-response-after = 1 s

	}
	cluster {
		seed-nodes = [
			# Set programatically (passed in on args list)
			# e.g.		"akka.tcp://ClusterSystem@127.0.0.1:2551"
		]
		auto-down-unreachable-after = 20m
	}
	scheduler {
		# The LightArrayRevolverScheduler is used as the default scheduler in the
		# system. It does not execute the scheduled tasks on exact time, but on every
		# tick, it will run everything that is (over)due. You can increase or decrease
		# the accuracy of the execution timing by specifying smaller or larger tick
		# duration. If you are scheduling a lot of tasks you should consider increasing
		# the ticks per wheel.
		# Note that it might take up to 1 tick to stop the Timer, so setting the
		# tick-duration to a high value will make shutting down the actor system
		# take longer.
		tick-duration = 10ms

		# The timer uses a circular wheel of buckets to store the timer tasks.
		# This should be set such that the majority of scheduled timeouts (for high
		# scheduling frequency) will be shorter than one rotation of the wheel
		# (ticks-per-wheel * ticks-duration)
		# THIS MUST BE A POWER OF TWO!
		ticks-per-wheel = 512

		# This setting selects the timer implementation which shall be loaded at
		# system start-up.
		# The class given here must implement the akka.actor.Scheduler interface
		# and offer a public constructor which takes three arguments:
		#  1) com.typesafe.config.Config
		#  2) akka.event.LoggingAdapter
		#  3) java.util.concurrent.ThreadFactory
		implementation = akka.actor.LightArrayRevolverScheduler

		# When shutting down the scheduler, there will typically be a thread which
		# needs to be stopped, and this timeout determines how long to wait for
		# that to happen. In case of timeout the shutdown of the actor system will
		# proceed without running possibly still enqueued tasks.
		shutdown-timeout = 5s
	}
}

akka-kryo-serialization {

	# Possible values for id-strategy are:
	# default, explicit, incremental, automatic
	id-strategy = "explicit"
	implicit-registration-logging = true

	# Define a default size for byte buffers used during serialization
	buffer-size = 16000

	# The serialization byte buffers are doubled as needed until they exceed
	# maxBufferSize and an exception is thrown. Can be -1 for no maximum.
	max-buffer-size = -1

	# To use a custom queue the [[io.altoo.akka.serialization.kryo.DefaultQueueBuilder]]
	# can be extended and registered here.
	#queue-builder = "io.altoo.akka.serialization.kryo.DefaultQueueBuilder"

	# If set, akka uses manifests to put a class name
	# of the top-level object into each message
	use-manifests = false


	# If enabled, Kryo logs a lot of information about serialization process.
	# Useful for debugging and low-level tweaking
	kryo-trace = false

	# If enabled, Kryo uses internally a map detecting shared nodes.
	# This is a preferred mode for big object graphs with a lot of nodes.
	# For small object graphs (e.g. below 10 nodes) set it to false for
	# better performance.
	kryo-reference-map = true

	# If enabled, allows Kryo to resolve subclasses of registered Types.
	#
	# This is primarily useful when id-strategy is set to "explicit". In this
	# case, all classes to be serialized must be explicitly registered. The
	# problem is that a large number of common Scala and Akka types (such as
	# Map and ActorRef) are actually traits that mask a large number of
	# specialized classes that deal with various situations and optimizations.
	# It isn't straightforward to register all of these, so you can instead
	# register a single supertype, with a serializer that can handle *all* of
	# the subclasses, and the subclasses get serialized with that.
	#
	# Use this with care: you should only rely on this when you are confident
	# that the superclass serializer covers all of the special cases properly.
	resolve-subclasses = false

	# Define mappings from a fully qualified class name to a numeric id.
	# Using ids instead of FQCN leads to smaller sizes of serialized representations
	# and faster serialization.
	#
	# This section is mandatory for idstartegy=explicit
	# This section is optional  for idstartegy=incremental
	# This section is ignored   for idstartegy=default
	#
	# The smallest possible id should start at 20 (or even higher), because
	# ids below it are used by Kryo internally e.g. for built-in Java and
	# Scala types.
	#
	# Some helpful mappings are provided through `supplied-basic-mappings`
	# and can be added/extended by:
	#
	 mappings =  {
		 "java.util.UUID" = 30

		 "java.time.LocalDate" = 31
		 "java.time.LocalDateTime" = 32
		 "java.time.LocalTime" = 33
		 "java.time.ZoneOffset" = 34
		 "java.time.ZoneRegion" = 35
		 "java.time.ZonedDateTime" = 36
		 "java.time.Instant" = 37
		 "java.time.Duration" = 38

		 // scala
		 "scala.Some" = 50
		 "scala.None$" = 51
		 "scala.util.Left" = 52
		 "scala.util.Right" = 53
		 "scala.util.Success" = 54
		 "scala.util.Failure" = 55

		 "scala.Tuple2" = 60
		 "scala.Tuple3" = 61
		 "scala.Tuple4" = 62
		 "scala.Tuple5" = 63
		 "scala.Tuple6" = 64
		 "scala.Tuple7" = 65
		 "scala.Tuple8" = 66
		 "scala.collection.immutable.Nil$" = 70
		 "scala.collection.immutable.$colon$colon" = 71
		 "scala.collection.immutable.Map$EmptyMap$" = 72
		 "scala.collection.immutable.Map$Map1" = 73
		 "scala.collection.immutable.Map$Map2" = 74
		 "scala.collection.immutable.Map$Map3" = 75
		 "scala.collection.immutable.Map$Map4" = 76
		 "scala.collection.immutable.Set$EmptySet$" = 77
		 "scala.collection.immutable.Set$Set1" = 78
		 "scala.collection.immutable.Set$Set2" = 79
		 "scala.collection.immutable.Set$Set3" = 80
		 "scala.collection.immutable.Set$Set4" = 81
		 "scala.Option$" = 82

	 }
	#
	#mappings {
		# fully.qualified.classname1 = id1
		# fully.qualified.classname2 = id2
	#}

	# Define a set of fully qualified class names for
	# classes to be used for serialization.
	# The ids for those classes will be assigned automatically,
	# but respecting the order of declaration in this section
	#
	# This section is optional  for idstartegy=incremental
	# This section is ignored   for idstartegy=default
	# This section is optional  for idstartegy=explicit
	classes = [
		"com.raphtory.core.components.leader.WatchDog$Message$RequestBuilderId$"
		"com.raphtory.core.components.leader.WatchDog$Message$ClusterStatusRequest$"
		"com.raphtory.core.components.leader.WatchDog$Message$RequestPartitionId$"
		"com.raphtory.core.components.leader.WatchDog$Message$RequestSpoutId$"
		"com.raphtory.core.components.leader.WatchDog$Message$RequestQueryId$"
		"com.raphtory.core.components.leader.WatchDog$Message$PartitionsCount"
		"com.raphtory.core.components.leader.WatchDog$Message$ClusterStatusResponse"
		"com.raphtory.core.components.leader.WatchDog$Message$AssignedId"
		"com.raphtory.core.components.leader.WatchDog$Message$BuilderUp"
		"com.raphtory.core.components.leader.WatchDog$Message$SpoutUp"
		"com.raphtory.core.components.leader.WatchDog$Message$QueryManagerUp"
		"com.raphtory.core.components.leader.WatchDog$Message$PartitionUp"
		"com.raphtory.core.components.leader.WatchDog$Message$RequestPartitionCount$"


		"com.raphtory.core.components.leader.WatermarkManager$Message$ProbeWatermark$"
		"com.raphtory.core.components.leader.WatermarkManager$Message$WatermarkTime$"
		"com.raphtory.core.components.leader.WatermarkManager$Message$SaveState$"
		"com.raphtory.core.components.leader.WatermarkManager$Message$WatermarkTime"


		"com.raphtory.core.components.spout.SpoutAgent$CommonMessage$SpoutOnline$"
		"com.raphtory.core.components.spout.SpoutAgent$CommonMessage$WorkPlease$"
		"com.raphtory.core.components.spout.SpoutAgent$CommonMessage$AllocateTuple"
		"com.raphtory.core.components.spout.SpoutAgent$CommonMessage$DataFinished$"
		"com.raphtory.core.components.spout.SpoutAgent$CommonMessage$NoWork$"

		"com.raphtory.core.components.graphbuilder.BuilderExecutor$CommonMessage$BuilderTimeSync"
		"com.raphtory.core.components.graphbuilder.BuilderExecutor$CommonMessage$DataFinishedSync"
		"com.raphtory.core.components.graphbuilder.BuilderExecutor$CommonMessage$KeepAlive$"

		"com.raphtory.core.model.graph.TrackedGraphUpdate"
		"com.raphtory.core.model.graph.VertexAdd"
		"com.raphtory.core.model.graph.EdgeAdd"
		"com.raphtory.core.model.graph.VertexDelete"
		"com.raphtory.core.model.graph.EdgeDelete"
		"com.raphtory.core.model.graph.Properties"
		"com.raphtory.core.model.graph.DoubleProperty"
		"com.raphtory.core.model.graph.ImmutableProperty"
		"com.raphtory.core.model.graph.StringProperty"
		"com.raphtory.core.model.graph.LongProperty"
		"com.raphtory.core.model.graph.DoubleProperty"
		"com.raphtory.core.model.graph.FloatProperty"
		"com.raphtory.core.model.graph.Type"

		"com.raphtory.core.model.graph.TrackedGraphEffect"
		"com.raphtory.core.model.graph.SyncNewEdgeAdd"
		"com.raphtory.core.model.graph.SyncExistingEdgeAdd"
		"com.raphtory.core.model.graph.SyncExistingEdgeRemoval"
		"com.raphtory.core.model.graph.SyncNewEdgeRemoval"
		"com.raphtory.core.model.graph.OutboundEdgeRemovalViaVertex"
		"com.raphtory.core.model.graph.InboundEdgeRemovalViaVertex"
		"com.raphtory.core.model.graph.SyncExistingRemovals"




		"com.raphtory.core.model.graph.EdgeSyncAck"
		"com.raphtory.core.model.graph.VertexRemoveSyncAck"

		"com.raphtory.core.model.graph.VertexMessage"
		"com.raphtory.core.components.querymanager.QueryHandler$Message$StartAnalysis$"
		"com.raphtory.core.components.querymanager.QueryHandler$Message$ReaderWorkersOnline$"
		"com.raphtory.core.components.querymanager.QueryHandler$Message$ReaderWorkersAck$"
		"com.raphtory.core.components.querymanager.QueryHandler$Message$LoadAnalyser"
		"com.raphtory.core.components.querymanager.QueryHandler$Message$ExecutorEstablished"
		"com.raphtory.core.components.querymanager.QueryHandler$Message$TimeCheck$"
		"com.raphtory.core.components.querymanager.QueryHandler$Message$TimeResponse"
		"com.raphtory.core.components.querymanager.QueryHandler$Message$RecheckTime$"
		"com.raphtory.core.components.querymanager.QueryHandler$Message$CreatePerspective"
		"com.raphtory.core.components.querymanager.QueryHandler$Message$PerspectiveEstablished$"
		"com.raphtory.core.components.querymanager.QueryHandler$Message$StartSubtask"
		"com.raphtory.core.components.querymanager.QueryHandler$Message$Ready"
		"com.raphtory.core.components.querymanager.QueryHandler$Message$SetupNextStep"
		"com.raphtory.core.components.querymanager.QueryHandler$Message$SetupNextStepDone$"
		"com.raphtory.core.components.querymanager.QueryHandler$Message$StartNextStep"
		"com.raphtory.core.components.querymanager.QueryHandler$Message$CheckMessages"
		"com.raphtory.core.components.querymanager.QueryHandler$Message$GraphFunctionComplete"
		"com.raphtory.core.components.querymanager.QueryHandler$Message$EndStep"
		"com.raphtory.core.components.querymanager.QueryHandler$Message$Finish"
		"com.raphtory.core.components.querymanager.QueryHandler$Message$ReturnResults"
		"com.raphtory.core.components.querymanager.QueryHandler$Message$StartNextSubtask$"

		"com.raphtory.core.components.querymanager.QueryHandler$Message$EstablishExecutor"
		"com.raphtory.core.components.querymanager.QueryHandler$Message$ExecutorEstablished"
		"com.raphtory.core.components.querymanager.QueryHandler$Message$StartGraph$"
		"com.raphtory.core.components.querymanager.QueryHandler$Message$TableBuilt$"
		"com.raphtory.core.components.querymanager.QueryHandler$Message$TableFunctionComplete$"
		"com.raphtory.core.components.querymanager.QueryHandler$Message$CreatePerspective"
		"com.raphtory.core.components.querymanager.QueryHandler$Message$PerspectiveEstablished$"

		"com.raphtory.core.components.querymanager.QueryManager$Message$PointQuery"
		"com.raphtory.core.components.querymanager.QueryManager$Message$RangeQuery"
		"com.raphtory.core.components.querymanager.QueryManager$Message$LiveQuery"
		"com.raphtory.core.components.querymanager.QueryManager$Message$EndQuery"
		"com.raphtory.core.components.querymanager.QueryManager$Message$QueryNotPresent"

        "com.raphtory.core.model.algorithm.Step"
        "com.raphtory.core.model.algorithm.Iterate"
        "com.raphtory.core.model.algorithm.VertexFilter"
        "com.raphtory.core.model.algorithm.Select"
        "com.raphtory.core.model.algorithm.TableFilter"
        "com.raphtory.core.model.algorithm.WriteTo"

		"com.raphtory.core.components.querymanager.QueryManager$Message$KillTask"
		"com.raphtory.core.components.querymanager.QueryManager$Message$JobKilled$"
		"com.raphtory.core.components.querymanager.QueryManager$Message$ResultsForApiPI"
		"com.raphtory.core.components.querymanager.QueryManager$Message$JobDoesntExist$"
		"com.raphtory.core.components.querymanager.QueryManager$Message$ManagingTask"
		"com.raphtory.core.components.querymanager.QueryManager$Message$AreYouFinished$"
		"com.raphtory.core.components.querymanager.QueryManager$Message$TaskFinished"
		"com.raphtory.core.components.querymanager.QueryManager$Message$JobFailed$"

        "com.raphtory.core.components.leader.WatermarkManager$Message$WhatsTheTime$"



		"com.raphtory.algorithms.PartitionState"

        "com.raphtory.dev.wordSemantic.spouts.Update"

		"scala.collection.mutable.TreeMap"
		"scala.None$"
		"scala.collection.immutable.$colon$colon"
		"scala.Tuple2"
		"scala.Tuple3"
		"scala.Tuple4"
		"scala.Tuple5"
		"scala.Tuple6"
		"scala.Tuple7"
		"scala.Tuple8"
		"scala.Array"
		"scala.collection.mutable.WrappedArray$ofRef"
		"scala.Tuple9"
		"scala.Tuple10"
		"scala.Tuple11"
		"scala.Tuple12"
		"scala.Tuple13"
		"scala.Tuple14"
		"scala.Tuple15"
		"scala.Tuple16"
		"scala.Tuple17"
		"scala.Tuple18"
		"scala.Tuple19"
		"scala.Tuple20"
		"scala.Tuple21"
		"scala.Tuple22"
		"scala.collection.mutable.ArrayBuffer"
		"akka.actor.RepointableActorRef"
		"akka.remote.RemoteActorRef"
		"scala.Tuple2$mcII$sp"
		"scala.Tuple2$mcJI$sp"
		"scala.Tuple2$mcJJ$sp"
		"scala.collection.mutable.HashMap"
		"scala.collection.parallel.immutable.ParHashMap"
		"scala.collection.immutable.HashMap$HashTrieMap"
		"scala.collection.parallel.mutable.ParArray"
		"scala.collection.mutable.ArraySeq"
		"scala.collection.immutable.HashMap$HashMap1"
	]

	# Note: even though only to be helpful, these mappings are considered
	# part of the api and changes are to be considered breaking the api
	optional-basic-mappings {
		// java

		#"scala.collection.immutable.ArraySeq$ofRef" = 82
		#"scala.collection.immutable.ArraySeq$ofInt" = 83
		#"scala.collection.immutable.ArraySeq$ofDouble" = 84
		#"scala.collection.immutable.ArraySeq$ofLong" = 85
		#"scala.collection.immutable.ArraySeq$ofFloat" = 86
		#"scala.collection.immutable.ArraySeq$ofChar" = 87
		#"scala.collection.immutable.ArraySeq$ofByte" = 88
		#"scala.collection.immutable.ArraySeq$ofShort" = 89
		#"scala.collection.immutable.ArraySeq$ofBoolean" = 90
		#"scala.collection.immutable.ArraySeq$ofUnit" = 91
	}



}



worker-dispatcher {
	# Dispatcher is the name of the event-based dispatcher
	type = Dispatcher
	# What kind of ExecutionService to use
	executor = "fork-join-executor"
	#mailbox-type = "com.raphtory.core.components.actor.SizeTrackedMailbox"
	# Configuration for the fork join pool
	fork-join-executor {
		# Min number of threads to cap factor-based parallelism number to
		parallelism-min = 2
		# Parallelism (threads) ... ceil(available processors * factor)
		parallelism-factor = 2.0
		# Max number of threads to cap factor-based parallelism number to
		parallelism-max = 10
	}
	throughput = 1
	# Throughput defines the maximum number of messages to be
	# processed per actor before the thread jumps to the next actor.
	# Set to 1 for as fair as possible.
}

reader-dispatcher {
	# Dispatcher is the name of the event-based dispatcher
	type = Dispatcher
	# What kind of ExecutionService to use
	executor = "fork-join-executor"
	# Configuration for the fork join pool
	fork-join-executor {
		# Min number of threads to cap factor-based parallelism number to
		parallelism-min = 2
		# Parallelism (threads) ... ceil(available processors * factor)
		parallelism-factor = 2.0
		# Max number of threads to cap factor-based parallelism number to
		parallelism-max = 10
	}
	# Throughput defines the maximum number of messages to be
	# processed per actor before the thread jumps to the next actor.
	# Set to 1 for as fair as possible.
	throughput = 1
}
builder-dispatcher {
	# Dispatcher is the name of the event-based dispatcher
	type = Dispatcher
	# What kind of ExecutionService to use
	executor = "fork-join-executor"
	# Configuration for the fork join pool
	fork-join-executor {
		# Min number of threads to cap factor-based parallelism number to
		parallelism-min = 2
		# Parallelism (threads) ... ceil(available processors * factor)
		parallelism-factor = 2.0
		# Max number of threads to cap factor-based parallelism number to
		parallelism-max = 10
	}
	# Throughput defines the maximum number of messages to be
	# processed per actor before the thread jumps to the next actor.
	# Set to 1 for as fair as possible.
	throughput = 1
}
misc-dispatcher {
	# Dispatcher is the name of the event-based dispatcher
	type = Dispatcher
	# What kind of ExecutionService to use
	executor = "fork-join-executor"
	# Configuration for the fork join pool
	fork-join-executor {
		# Min number of threads to cap factor-based parallelism number to
		parallelism-min = 2
		# Parallelism (threads) ... ceil(available processors * factor)
		parallelism-factor = 2.0
		# Max number of threads to cap factor-based parallelism number to
		parallelism-max = 10
	}
	# Throughput defines the maximum number of messages to be
	# processed per actor before the thread jumps to the next actor.
	# Set to 1 for as fair as possible.
	throughput = 1
}
analysis-dispatcher {
	# Dispatcher is the name of the event-based dispatcher
	type = Dispatcher
	# What kind of ExecutionService to use
	executor = "fork-join-executor"
	# Configuration for the fork join pool
	fork-join-executor {
		# Min number of threads to cap factor-based parallelism number to
		parallelism-min = 2
		# Parallelism (threads) ... ceil(available processors * factor)
		parallelism-factor = 2.0
		# Max number of threads to cap factor-based parallelism number to
		parallelism-max = 10
	}
	# Throughput defines the maximum number of messages to be
	# processed per actor before the thread jumps to the next actor.
	# Set to 1 for as fair as possible.
	throughput = 1
}
spout-dispatcher {
	# Dispatcher is the name of the event-based dispatcher
	type = Dispatcher
	# What kind of ExecutionService to use
	executor = "fork-join-executor"
	# Configuration for the fork join pool
	fork-join-executor {
		# Min number of threads to cap factor-based parallelism number to
		parallelism-min = 2
		# Parallelism (threads) ... ceil(available processors * factor)
		parallelism-factor = 2.0
		# Max number of threads to cap factor-based parallelism number to
		parallelism-max = 10
	}
	# Throughput defines the maximum number of messages to be
	# processed per actor before the thread jumps to the next actor.
	# Set to 1 for as fair as possible.
	throughput = 10
}
