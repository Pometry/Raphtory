{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting data into a graph\n",
    "\n",
    "Now that we know PyRaphtory is installed and running, let's look at the different ways to get some real data into a graph. \n",
    "\n",
    "For this first set of tutorials we are going to be building graphs from a Lord of the Rings dataset, looking at when characters interact throughout the trilogy üßùüèª‚Äç‚ôÄÔ∏èüßôüèª‚Äç‚ôÇÔ∏èüíç.\n",
    " \n",
    "<p align=\"center\">\n",
    " <img src=\"../images/lotr-graphic.png\" width=\"700px\" style=\"padding: 15px\" alt=\"Intro Graphic of LOTR slices\"/>\n",
    "</p>\n",
    "\n",
    "As with the quick start install guide, this and all following python pages are built as iPython notebooks. If you want to follow along on your own machine, click the `open on github` link in the top right of this page.\n",
    "\n",
    "## Let's have a look at the example data\n",
    "\n",
    "The data we are going to use is two `csv` files which will be pulled from our <a href=\"https://github.com/Raphtory/Data\">Github data repository</a>. These are the structure of the graph (`lotr.csv`) and some metadata about the characters (`lotr_properties.csv`)\n",
    "\n",
    "For the structure file each line contains two characters that appeared in the same sentence, along with the sentence number, which we will use as a `timestamp`. The first line of the file is `Gandalf,Elrond,33` which tells us that Gandalf and Elrond appears together in sentence 33.\n",
    "\n",
    "For the properties file each line gives a characters name, their race and gender. For example `Gimli,dwarf,male`.\n",
    "\n",
    "\n",
    "### Downloading the csv from Github üíæ\n",
    "\n",
    "The following `curl` command will download the csv files and save them in the `tmp` directory on your computer. This will be deleted when you restart your computer, but it's only a couple of KB in any case.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****Downloading Data****\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 52206  100 52206    0     0   256k      0 --:--:-- --:--:-- --:--:--  256k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   686  100   686    0     0   3853      0 --:--:-- --:--:-- --:--:--  3832 0\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 69632  100 69632    0     0   500k      0 --:--:-- --:--:-- --:--:--  500k\n",
      "****LOTR GRAPH STRUCTURE****\n",
      "Gandalf,Elrond,33\n",
      "Frodo,Bilbo,114\n",
      "Blanco,Marcho,146\n",
      "****LOTR GRAPH PROPERTIES****\n",
      "Aragorn,men,male\n",
      "Gandalf,ainur,male\n",
      "Goldberry,ainur,female\n"
     ]
    }
   ],
   "source": [
    "print(\"****Downloading Data****\")\n",
    "!curl -o /tmp/lotr.csv https://raw.githubusercontent.com/Raphtory/Data/main/lotr.csv\n",
    "!curl -o /tmp/lotr_properties.csv https://raw.githubusercontent.com/Raphtory/Data/main/lotr_properties.csv\n",
    "!curl -o /tmp/lotr.db https://raw.githubusercontent.com/Raphtory/Data/main/lotr.db\n",
    "print(\"****LOTR GRAPH STRUCTURE****\")\n",
    "!head -n 3 /tmp/lotr.csv\n",
    "print(\"****LOTR GRAPH PROPERTIES****\")\n",
    "!head -n 3 /tmp/lotr_properties.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up our imports and Raphtory Context\n",
    "Now that we have our data we can sort out our imports and create the `Raphtory Context` which we will use to build our graphs.\n",
    "\n",
    "The imports are for parsing CSV files, accessing pandas dataframes, and bringing in all the Raphtory classes we will use in the tutorial.\n",
    "\n",
    "The filenames are pointing at the data we just downloaded. If you change the download location above, make sure to change them here as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from pyraphtory.context import PyRaphtory\n",
    "from pyraphtory.input import ImmutableString\n",
    "from pyraphtory.input import GraphBuilder\n",
    "from pyraphtory.spouts import FileSpout\n",
    "from pyraphtory.sources import CSVEdgeListSource\n",
    "from pyraphtory.sources import Source\n",
    "from pyraphtory.sources import SqlEdgeSource\n",
    "from pyraphtory.sources import SqliteConnection\n",
    "from pyraphtory.sources import SqlVertexSource\n",
    "\n",
    "structure_file = \"/tmp/lotr.csv\"\n",
    "properties_file = \"/tmp/lotr_properties.csv\"\n",
    "ctx = PyRaphtory.local()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding data directly into the Graph\n",
    "\n",
    "The simplest way to add data into a graph is to directly call the `add_vertex` and `add_edge` functions, which we saw in the quick start guide. These have required arguments defining the time the addition occurred and an identifier for the entity being updated. These functions, however, have several optional arguments allowing us to add `properties` and `types` on top of the base structure. Raphtory also allows for a secondary time index for disambiguating event ordering, this defaults to the number of prior updates sent +1.\n",
    "\n",
    "| Function     | Required Arguments            | Optional Arguments                           |\n",
    "|--------------|-------------------------------|----------------------------------------------|\n",
    "| `add_vertex` | `timestamp`,`vertex_id`       | `properties`,`vertex_type`,`secondary_index` |\n",
    "| `add_edge`   | `timestamp`,`src_id`,`dst_id` | `properties`,`edge_type`,`secondary_index`   |\n",
    "\n",
    "\n",
    "Lets take a look at this with our example data. In the below code we are opening The Lord of The Rings structural data via the csv reader and looping through each line. \n",
    "\n",
    "To insert the data we:\n",
    "\n",
    "* Extract the two characters names, referring to them as the `source_node` and `destination_node`.\n",
    "* Extract the sentence number, referring to is as `timestamp`. This is then cast to an `int` as timestamps in Raphtory must be a number.\n",
    "* Call `add_vertex` for both nodes, setting their type to `Character`.\n",
    "* Creating an edge between them via `add_edge` and labelling this a `Co-occurence`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = ctx.new_graph()\n",
    "with open(structure_file, 'r') as csvfile:\n",
    "    datareader = csv.reader(csvfile)\n",
    "    for row in datareader:\n",
    "\n",
    "        source_node = row[0]\n",
    "        destination_node = row[1]\n",
    "        timestamp = int(row[2])\n",
    "        \n",
    "        graph.add_vertex(timestamp, source_node, vertex_type=\"Character\")\n",
    "        graph.add_vertex(timestamp, destination_node, vertex_type=\"Character\")  \n",
    "        graph.add_edge(timestamp, source_node, destination_node, edge_type=\"Character_Co-occurence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's see if the data has ingested\n",
    "\n",
    "To do this, much like the quick start, we can run a query on our graph. As Raphtory allows us to explore the network's history, lets add a bit of this in as well. \n",
    "\n",
    "Below we create a function to extract the first appearance of a character. This takes a vertex and calls `name()` and `earliest_activity()`. These return the name we gave in the `add_vertex` calls above and a `HistoricEvent` object. This object contains the sentence the character was introduced (`.time()`) and the update this was in our data (`.index()`). In this function, we set a `state` on each vertex with these properties. \n",
    "\n",
    "Once defined we can call `select` on our graph and select columns of interest for all vertices, followed by a call to `to_df` which returns a dataframe with our results.\n",
    "\n",
    "You will see in the results we have a `timestamp` column, this is because both updates and queries **must** happen at a given time. This defaults to the latest time in the data, `32674` in our case. Don't worry too much about the details of Raphtory queries here, we will get into this in the coming tutorials.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select0() takes 2 positional arguments but 4 were given\n",
      "select1() takes 2 positional arguments but 4 were given\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No overloaded implementations matched for select with args=('name', 'earliest_appearance', 'index') and kwargs={}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m     vertex\u001b[39m.\u001b[39mset_state(\u001b[39m\"\u001b[39m\u001b[39mearliest_appearance\u001b[39m\u001b[39m\"\u001b[39m, event\u001b[39m.\u001b[39mtime())\n\u001b[1;32m      5\u001b[0m     vertex\u001b[39m.\u001b[39mset_state(\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m, event\u001b[39m.\u001b[39mindex())\n\u001b[0;32m----> 7\u001b[0m first_appearance_df \u001b[39m=\u001b[39m graph\u001b[39m.\u001b[39;49mstep(characters_first_appearance)\u001b[39m.\u001b[39;49mselect(\u001b[39m\"\u001b[39;49m\u001b[39mname\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mearliest_appearance\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mindex\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39mto_df() \n",
      "File \u001b[0;32m~/miniconda3/envs/test_env/lib/python3.9/site-packages/pyraphtory/interop.py:552\u001b[0m, in \u001b[0;36mOverloadedMethod.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m errors:\n\u001b[1;32m    551\u001b[0m     \u001b[39mprint\u001b[39m(e)\n\u001b[0;32m--> 552\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo overloaded implementations matched for \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m with \u001b[39m\u001b[39m{\u001b[39;00margs\u001b[39m=}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00mkwargs\u001b[39m=}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No overloaded implementations matched for select with args=('name', 'earliest_appearance', 'index') and kwargs={}"
     ]
    }
   ],
   "source": [
    "def characters_first_appearance(vertex):\n",
    "    vertex.set_state(\"name\",vertex.name())\n",
    "    event = vertex.earliest_activity()\n",
    "    vertex.set_state(\"earliest_appearance\", event.time())\n",
    "    vertex.set_state(\"index\", event.index())\n",
    "\n",
    "first_appearance_df = graph.step(characters_first_appearance).select(\"name\", \"earliest_appearance\",\"index\").to_df() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating graphs, merging datasets and adding properties\n",
    "\n",
    "One cool thing about Raphtory is that we can freely insert new information at any point in time and it will be automatically inserted in chronological order. This makes it really easy to merge datasets or ingest out of order data. \n",
    "\n",
    "Raphtory currently support several types of `mutable` properties which can change throughout the lifetime of a vertex or edge, giving them a history to be explored. We also allow the user to specify `immutable` properties which only have one value, useful for meta data and saving memory! All property objects require the user to specify a name and value. The current supported properties include:\n",
    "\n",
    "* `MutableString()`\n",
    "* `MutableLong()`\n",
    "* `MutableDouble()`\n",
    "* `MutableBoolean()`\n",
    "* `ImmutableString()` \n",
    "\n",
    "To explore this and to add some properties to our graph, lets load our second dataset!\n",
    "\n",
    "Below we are opening our property file the same way as the first. As we don't have any time to work with in this data we will have to create some of our own. We have two options, we can say it all happens at time `1` or we can use the results of our **earliest appearance** query to decide when to insert the properties. \n",
    "\n",
    "For the latter we have zipped the `name` and `earliest_timestamp` columns from our dataframe and turned them into a `dict` where we can look up the best timestamps for each character.\n",
    "\n",
    "For each line we then:\n",
    "\n",
    "* Get the name and look it up in our dict to get the timestamp.\n",
    "* Get the race and gender from the data and wrap them in an `ImmutableString` as they are unchanging metadata, so no need to maintain a history.\n",
    "* Call `add_vertex` passing all of this information.\n",
    "\n",
    "Now it's worthwhile noting that we aren't calling a function called `update_vertex` or something similar, even though we know the vertex exists. This is because everything is considered an addition into the history and Raphtory sorts all the ordering internally!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earliest_appearence = dict(zip(first_appearance_df.name,first_appearance_df.earliest_appearance))\n",
    "\n",
    "with open(properties_file, 'r') as csvfile:\n",
    "    datareader = csv.reader(csvfile)\n",
    "    for row in datareader:\n",
    "        name = row[0]\n",
    "        timestamp = earliest_appearence[name]        \n",
    "        race = ImmutableString(\"race\",row[1])\n",
    "        gender = ImmutableString(\"gender\",row[2])\n",
    "        graph.add_vertex(timestamp, name, properties=[race,gender])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using our properties as part of a query\n",
    "To quickly see if our new properties are included in the graph we can write a new query! Lets have a look at the dwarves who have the most interactions.\n",
    "\n",
    "To start we can create a function which for each vertex sets a state of its name and the length of its `history()` i.e. the number of updates it has had. As we have one update per interaction, this will give us a quick count of the total interactions throughout the books.\n",
    "\n",
    "This function can be given to the `step` applied to the graph as before, but first let's apply a `vertex_filter()` which will check the value for the **race** property and remove anyone who isn't a **dwarf**.\n",
    "\n",
    "Finally, we can use the `select` function to choose the columns we want in our dataframe and sort our dataframe by the number of interactions to see **Gimli** has by far the most!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def and_my_axe(vertex):\n",
    "    vertex.set_state(\"name\",vertex.name())\n",
    "    vertex.set_state(\"interactions\", len(vertex.history()))\n",
    "\n",
    "popular_dwarves = graph \\\n",
    "    .vertex_filter(lambda vertex: vertex.get_property_or_else(\"race\",\"unknown\") == \"dwarf\")\\\n",
    "    .step(and_my_axe) \\\n",
    "    .select(\"name\", \"interactions\") \\\n",
    "    .to_df() \n",
    "\n",
    "popular_dwarves.sort_values(by=\"interactions\",ascending=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingesting data with Sources\n",
    "\n",
    "Inserting updates one by one works for small datasets like this Lord of The Rings graph, but it isn't the most efficient way to parse your data. To enable you to work with large datasets we provide the `Source` API. `Sources` let you define where to pull data from and how to convert each tuple into `graph updates`. Raphtory can then handle batching and other speed-ups internally.  \n",
    "\n",
    "`Sources` take two arguments:\n",
    " \n",
    " * A `Spout` - which defines the location of the data.\n",
    " * A `GraphBuilder` - which contains your parsing function. \n",
    "\n",
    "We will come onto custom builders in a second, as if your data exists in a standard graph format, there is a good chance Raphtory already has one defined! For instance, the `lotr.csv` file we used above is in an `edge list` format, so we may use the `CSVEdgeListSource`. This particular source will parse each line as two `vertex additions` and an `edge addition` at the given timestamp. By default the timestamp is assumed to be at the end of the line, but this can be changed via arguments.\n",
    "\n",
    "In the below code we:\n",
    "\n",
    "* Create a new graph called `edge_list_graph`. \n",
    "* Create a `FileSpout`, giving it the `structure_file`. \n",
    "* Create the `CSVEdgeListSource` and hand it the `FileSpout` which it will use to pull the data.\n",
    "* Connect the source to the graph by calling the `load()` function.\n",
    "* Check the `Source` has ingested the data by running our **earliest appearance** query. \n",
    "\n",
    "It is worth noting here:\n",
    "\n",
    "* We can pass the `FileSpout` several more advanced options such as a directory of files, a filepath Regex etc. and it will pull in all files which match. \n",
    "* `load()` can be called as many times as you like on the graph with difference spouts and builders, allowing you to merge data from multiple sources.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_list_graph = ctx.new_graph()\n",
    "\n",
    "spout = FileSpout(structure_file)\n",
    "source = CSVEdgeListSource(spout,source_index=0,target_index=1,time_index=2,delimiter=\",\",header=False) \n",
    "\n",
    "edge_list_graph.load(source)\n",
    "\n",
    "edge_list_graph \\\n",
    "    .step(characters_first_appearance) \\\n",
    "    .select(\"name\", \"earliest_appearance\",\"index\") \\\n",
    "    .to_df() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingesting from SQL databases\n",
    "\n",
    "For some data sources, where connections can quickly become quite convoluted, we have created an additional set of wrappers to make things as simple as possible. A perfect example of this is for querying an SQL database and converting the output into a graph. Instead of wrangling with different connectors, structures and return types we provide the `SqlEdgeSource` and `SqlVertexSource` which require only basic connection information, an SQL query and what the returned columns map to. \n",
    "\n",
    "Looking at a concrete instance of this below, we ingest data from a SQLite database stored in the file 'lotr.db', which we downloaded at the start of this tutorial. This has exactly the same data as 'lotr.csv'.\n",
    "\n",
    "Firstly, in order to connect to it, we need to create a `SqliteConnection` so Raphtory knows how to access the data. In this case, the only thing we need to provide is the path to the file. If we were to use another database instead, such as Postgres, we would use a `PostgresConnection` and provide the hostname, port, etc.\n",
    "\n",
    "With the connection defined, we give our query (selecting all columns) to an `SqlEdgeSource` along with the name of the columns we want to use for the source/target IDs and the timestamp. We could additionally provide column names for types or properties if required. **Note:** This Source will handle conversion between Datetime and Epochs for the timestamps, Integer/Strings for the IDs and all data types for the properties. \n",
    "\n",
    "As we don't have any additional information for the vertices in this file we do not need to use an `SqlVertexSource`, the vertex additions will be automatically generated. If we wanted to add in the properties via a different table/database it would just be add an additional call to `sql_graph.load()` providing a second SQL query. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new graph\n",
    "sql_graph = ctx.new_graph()\n",
    "\n",
    "# Create a connection to the Sqlite database\n",
    "sqlite = SqliteConnection('/tmp/lotr.db')\n",
    "\n",
    "# Define the query we are going to use. We are going to return all the columns from lotr table\n",
    "query = 'select * from lotr'\n",
    "\n",
    "# Load the edges from the table using the 'source' and 'target' as source/target pair and 'line' as the time information\n",
    "sql_graph.load(SqlEdgeSource(sqlite, query, source='source', target='target', time='line'))\n",
    "\n",
    "# And finally, let's check that we successfully ingested the data applying characters_first_appearance algorithm again\n",
    "sql_graph.step(characters_first_appearance).select(\"name\", \"earliest_appearance\",\"index\").to_df() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating custom Sources\n",
    "\n",
    "Finally, lets wrap up this tutorial by combining everything we have already learnt with some custom sources! The next bit of code is chunkier than before so we have put comments inline to make it easier to follow along.\n",
    "\n",
    "As explained above, the generic `Source` object takes two arguments. We have already worked with the `FileSpout` which we can reuse here, so lets focus on the second argument, the `GraphBuilder`.\n",
    "\n",
    "`GraphBuilders` require you to provide a function which takes two arguments a `graph` and a `tuple`. The graph here is the same class that we have been using to add updates individually, so the functions are exactly the same. The `tuple` is a singular piece of data which is going to be output from the `Spout`. In our case the spout is going to produce strings, one for each line in the file we give it.\n",
    "\n",
    "Below we create two custom sources, once for each file we have been working with, requiring two parsing functions. These functions are almost an exact copy and paste from above, however we don't need the for-loop as we only need to think on the level of a singular line.\n",
    "\n",
    "The full pipeline of analysis has been recreated to enable this to run as a standalone script. \n",
    "\n",
    "Once you are comfortable with everything here, continue onto the next tutorial to get started on some real temporal queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First define our query functions\n",
    "def characters_first_appearance(vertex):\n",
    "    vertex.set_state(\"name\",vertex.name())\n",
    "    event = vertex.earliest_activity()\n",
    "    vertex.set_state(\"earliest_appearance\", event.time())\n",
    "    vertex.set_state(\"index\",event.index())\n",
    "\n",
    "def and_my_axe(vertex):\n",
    "    vertex.set_state(\"name\",vertex.name())\n",
    "    vertex.set_state(\"interactions\",len(vertex.history()))\n",
    "\n",
    "#Create a new graph\n",
    "custom_source_graph = ctx.new_graph()\n",
    "\n",
    "#Define the first graph builder parsing function which is going to handle the structure_file\n",
    "def parse_structure(graph, tuple: str):\n",
    "    row = [v.strip() for v in tuple.split(\",\")]\n",
    "    source_node = row[0]\n",
    "    destination_node = row[1]\n",
    "    timestamp = int(row[2])\n",
    "        \n",
    "    graph.add_vertex(timestamp, source_node, vertex_type=\"Character\")\n",
    "    graph.add_vertex(timestamp, destination_node, vertex_type=\"Character\")  \n",
    "    graph.add_edge(timestamp, source_node, destination_node, edge_type=\"Character_Co-occurence\")\n",
    "\n",
    "#Create a new FileSpout for the structure file\n",
    "structure_spout = FileSpout(structure_file)\n",
    "#Create a custom source, giving it the structure_spout and a GraphBuilder with our function to parse the structure_file\n",
    "structure_graph_builder = GraphBuilder(parse_structure)\n",
    "structure_source = Source(structure_spout,structure_graph_builder)\n",
    "#Connect our structure_source to our graph\n",
    "custom_source_graph.load(structure_source)\n",
    "\n",
    "#Run the earliest appearance query on our new graph so we can use it in the second parser\n",
    "first_appearance_df = graph \\\n",
    "    .step(characters_first_appearance) \\\n",
    "    .select(\"name\", \"earliest_appearance\",\"index\") \\\n",
    "    .to_df() \n",
    "earliest_appearence = dict(zip(first_appearance_df.name,first_appearance_df.earliest_appearance))\n",
    "\n",
    "\n",
    "#Define the second parsing function to handle the properties_files\n",
    "def parse_properties(graph, tuple: str):\n",
    "    row = [v.strip() for v in tuple.split(\",\")]\n",
    "    name = row[0]\n",
    "    timestamp = earliest_appearence[name]        \n",
    "    race = ImmutableString(\"race\",row[1])\n",
    "    gender = ImmutableString(\"gender\",row[2])\n",
    "    graph.add_vertex(timestamp, name, properties=[race,gender])\n",
    "\n",
    "#Create a second FileSpout for the properties_file\n",
    "property_spout = FileSpout(properties_file)\n",
    "#Create a source for the property_spout with a graph builder which uses our second parsing function\n",
    "property_graph_builder = GraphBuilder(parse_properties)\n",
    "property_source = Source(property_spout,property_graph_builder)\n",
    "#Load our properties_file into the graph\n",
    "custom_source_graph.load(property_source)\n",
    "\n",
    "#Finally, we can run our popular_dwarves query and get out the result!\n",
    "popular_dwarves = graph \\\n",
    "    .vertex_filter(lambda vertex: vertex.get_property_or_else(\"race\",\"unknown\") == \"dwarf\")\\\n",
    "    .step(and_my_axe) \\\n",
    "    .select(\"name\", \"interactions\")\\\n",
    "    .to_df() \n",
    "\n",
    "popular_dwarves.sort_values(by=\"interactions\",ascending=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "94770984c12f6e6b19bc1482bcaedab9430b32e2bb01a924f41ad834c2f22dc0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
